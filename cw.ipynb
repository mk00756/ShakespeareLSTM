{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded!\n",
      "Reducing corpus...\n",
      "Reduced corpus:\n",
      "[' ', '!', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Data sample:\n",
      " paces: those opposed eyes, which, like the meteors of a troubled heaven, all of one nature, of one substance bred, did lately meet in the intestine shock and furious close of civil butchery shall now, in mutual well-beseeming ranks, march all one way and be no more opposed against acquaintance, kindred and allies: the edge of war, like an ill-sheathed knife, no more shall cut his master. therefore, friends, as far as to the sepulchre of christ, whose soldier now, under whose blessed cross we ar\n",
      "Getting samples...\n",
      "Compiling model...\n",
      "Training model (may take a while)...\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 182s 365us/step - loss: 2.2019 - acc: 0.3624\n",
      "After 0 epochs, model generated:\n",
      "er with the farther the fall the fall the fall the fall the fall the fall the fall the fall the fall the fall the fall the fall the fall the fall the fall the fall the fall the fall the fall the fall \n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 181s 363us/step - loss: 1.8252 - acc: 0.4527\n",
      "After 1 epochs, model generated:\n",
      "ord the forth and the for the dound and the for the dound and the for the dound and the for the dound and the for the dound and the for the dound and the for the dound and the for the dound and the fo\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 183s 367us/step - loss: 1.6820 - acc: 0.4903\n",
      "After 2 epochs, model generated:\n",
      "unt and the death the hands and the death the hands and the death the hands and the death the hands and the death the hands and the death the hands and the death the hands and the death the hands and \n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 185s 369us/step - loss: 1.5977 - acc: 0.5140\n",
      "After 3 epochs, model generated:\n",
      " in the prince of the country that the death of the proud shall be the death, and the death of the proud shall be the death, and the death of the proud shall be the death, and the death of the proud s\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 181s 363us/step - loss: 1.5397 - acc: 0.5295\n",
      "After 4 epochs, model generated:\n",
      "ed and the searth and the searth the strong and the searth and the searth the strong and the searth and the searth the strong and the searth and the searth the strong and the searth and the searth the\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 183s 367us/step - loss: 1.4994 - acc: 0.5399\n",
      "After 5 epochs, model generated:\n",
      ", and the lord of your hands and the son of the son of the son, the son of the son of the son, the son of the son of the son, the son of the son of the son, the son of the son of the son, the son of t\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 184s 369us/step - loss: 1.4707 - acc: 0.5481\n",
      "After 6 epochs, model generated:\n",
      "ess to the counterfeit the counterfeit the counterfeit the counterfeit the counterfeit the counterfeit the counterfeit the counterfeit the counterfeit the counterfeit the counterfeit the counterfeit t\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 184s 368us/step - loss: 1.4432 - acc: 0.5553\n",
      "After 7 epochs, model generated:\n",
      "est that the strength the sent to the strength, and the sent thou art the sent to the strength, and the sent thou art the sent to the strength, and the sent thou art the sent to the strength, and the \n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 183s 365us/step - loss: 1.4233 - acc: 0.5600\n",
      "After 8 epochs, model generated:\n",
      "eating to the state of the company to the state of the company to the state of the company to the state of the company to the state of the company to the state of the company to the state of the compa\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 182s 365us/step - loss: 1.4048 - acc: 0.5652\n",
      "After 9 epochs, model generated:\n",
      "ist that the duke of york and the see the see the see the duke of york and the see the see the see the duke of york and the see the see the see the duke of york and the see the see the see the duke of\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 185s 370us/step - loss: 1.3907 - acc: 0.5694\n",
      "After 10 epochs, model generated:\n",
      "ue and stand and stand and stand and stand and stand and stand and stand and stand and stand and stand and stand and stand and stand and stand and stand and stand and stand and stand and stand and sta\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 184s 368us/step - loss: 1.3751 - acc: 0.5733\n",
      "After 11 epochs, model generated:\n",
      "y, and the duke of york and the strength and the strong and the strong and the strong and the strong and the strong and the strong and the strong and the strong and the strong and the strong and the s\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 186s 371us/step - loss: 1.3635 - acc: 0.5765\n",
      "After 12 epochs, model generated:\n",
      "le and the seas of the soul and the seas of the soul and the seas of the soul and the seas of the soul and the seas of the soul and the seas of the soul and the seas of the soul and the seas of the so\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 183s 366us/step - loss: 1.3529 - acc: 0.5793\n",
      "After 13 epochs, model generated:\n",
      "ery to the field. exit scene ii. london. the prince of wales, but the field of such a state of the field. enter the prince of wales, and so so far and so much as the see is the see and see the see in \n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 183s 366us/step - loss: 1.3432 - acc: 0.5809\n",
      "After 14 epochs, model generated:\n",
      "e the see the state of the sons of the state. the see is the son of the sons of the state. the see is the son of the sons of the state. the see is the son of the sons of the state. the see is the son \n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 186s 372us/step - loss: 1.3350 - acc: 0.5841\n",
      "After 15 epochs, model generated:\n",
      "ord and the counterfeit, the counterfeit our soldiers shall be the son of the soul, the subjects and the duke of york and the counterfulling the soul and thee that shall be so and so strike offender a\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 183s 366us/step - loss: 1.3269 - acc: 0.5861\n",
      "After 16 epochs, model generated:\n",
      " of 2s. the sons of my lord of welcome the state of the country for the country and the soul of his body of the country for the country and the sons of my lord of wellowhat and soldiers that i will be\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 185s 369us/step - loss: 1.3208 - acc: 0.5876\n",
      "After 17 epochs, model generated:\n",
      "ort, and the duke of york and the duke of york and the state of the court of gloucester, and the duke of york and the duke of york and the state of the court of gloucester, and the duke of york and th\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 185s 370us/step - loss: 1.3162 - acc: 0.5886\n",
      "After 18 epochs, model generated:\n",
      "ass and are the court of such a prince of warwick, who shall be the son of march and the court of the court, and so shall i see thee that the court of the court of the court, and so shall i see thee t\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 182s 364us/step - loss: 1.3073 - acc: 0.5912\n",
      "After 19 epochs, model generated:\n",
      "y, and then the common the stand and the duke of suffolk, and the common the state of the common that stand but the state of the commoning of the son, and then the common that shall be the son of the \n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 183s 365us/step - loss: 1.3017 - acc: 0.5929\n",
      "After 20 epochs, model generated:\n",
      "enting somerset and the see the see is the see that have the son of the court of the country and the seas and the third to the sons that shall be the son of the sons of the court of the country and th\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 181s 363us/step - loss: 1.2985 - acc: 0.5939\n",
      "After 21 epochs, model generated:\n",
      "ess than the state of the seas and subject to the king, and the see in the seas and subject to the king and subject to the king, and the see in the seas and subject to the king and subject to the king\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000/500000 [==============================] - 179s 358us/step - loss: 1.2938 - acc: 0.5951\n",
      "After 22 epochs, model generated:\n",
      "uelly and the see and so henry the seas of me in the country and the see in the country and the see in the country and the see in the country and the see in the country and the see in the country and \n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 180s 360us/step - loss: 1.2905 - acc: 0.5954\n",
      "After 23 epochs, model generated:\n",
      "eds, and then the father was a subject for the son of heaven to the king, and therefore is the cardinal of warwick, and somerset and the counterfeiting the state of the court of the face, and therefor\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 180s 361us/step - loss: 1.2858 - acc: 0.5971\n",
      "After 24 epochs, model generated:\n",
      "coning on the country and the soul of heart of the court of the state. the see is the soul of heart of the court of the state. the see is the soul of heart of the court of the state. the see is the so\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 181s 362us/step - loss: 1.2841 - acc: 0.5977\n",
      "After 25 epochs, model generated:\n",
      "ons, and then the see i shall be so fair more than the duke of york, and the see i shall be so fair more than the duke of york, and the see i shall be so fair more than the duke of york, and the see i\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 182s 364us/step - loss: 1.2809 - acc: 0.5978\n",
      "After 26 epochs, model generated:\n",
      "est death, and therefore i will not so dishonour and the son of the field and soldiers so for the soldiers be a soldier of the field. what say'st thou, march, and therefore i will not so dishonour and\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 182s 364us/step - loss: 1.2774 - acc: 0.5991\n",
      "After 27 epochs, model generated:\n",
      "n. enter a man and soldiers so that i will be the see that i will be the see that i will be the see that i will be the see that i will be the see that i will be the see that i will be the see that i w\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 179s 358us/step - loss: 1.2736 - acc: 0.6002\n",
      "After 28 epochs, model generated:\n",
      "rdering son, and the state of the state of the field. what things the country than a shalle of the state of the state of the state of thee, and therefore i have been a straight to the state of the fat\n",
      "Epoch 1/1\n",
      "500000/500000 [==============================] - 181s 362us/step - loss: 1.2711 - acc: 0.6006\n",
      "After 29 epochs, model generated:\n",
      "en that the state of the field of the field. alarum. exeunt scene iii. london. the palace. enter the sount should be the state of the state. the sun in the field of the field. what say you to the prot\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import keras\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "\n",
    "def char_to_one_hot(char, corpus):\n",
    "    arr = np.zeros((len(corpus)))\n",
    "    hot_index = corpus.index(char)\n",
    "    arr[hot_index] = 1\n",
    "    return arr\n",
    "\n",
    "def one_hot_to_char(one_hot, corpus):\n",
    "    best_index = np.argmax(one_hot)\n",
    "    return corpus[best_index]\n",
    "\n",
    "def from_window_to_one_hot(window, corpus):\n",
    "    corpus_size = len(corpus)\n",
    "    \n",
    "    text = window[0]\n",
    "    next_char = window[1]\n",
    "    \n",
    "    text_array = np.zeros((len(text), corpus_size))\n",
    "    for idx, char in enumerate(text):\n",
    "        text_array[idx] = char_to_one_hot(char, corpus)\n",
    "    \n",
    "    next_char_arr = char_to_one_hot(next_char, corpus)\n",
    "    \n",
    "    return text_array, next_char_arr\n",
    "\n",
    "def get_window(text, starting_index, window_size):\n",
    "    window = text[starting_index : starting_index+window_size]\n",
    "    next_character = text[starting_index+window_size]\n",
    "    return window, next_character\n",
    "\n",
    "def generate_sample(model, sample_len=200, initial_window=None):\n",
    "    if initial_window is None:\n",
    "        #Generate random string from lowercase letters and numbers\n",
    "        initial_window = ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(window_size))\n",
    "    \n",
    "    #String holding only letters predicted by the model\n",
    "    predicted_text = \"\"\n",
    "    \n",
    "    for i in range(sample_len):\n",
    "        X,y = from_window_to_one_hot((initial_window,\"a\"), corpus)\n",
    "        X = X.reshape((1,window_size, corpus_size))\n",
    "        pred_char_raw = model.predict(X)\n",
    "        pred_char = one_hot_to_char(pred_char_raw, corpus)\n",
    "\n",
    "        initial_window = initial_window[1:]\n",
    "        initial_window = initial_window+pred_char\n",
    "\n",
    "        predicted_text += pred_char\n",
    "    \n",
    "    return predicted_text\n",
    "\n",
    "print(\"Loading data...\")\n",
    "with open('data/all_lines.txt', 'r', encoding='utf-8', errors='ignore') as speech_file:\n",
    "    text=speech_file.read()\n",
    "\n",
    "print(\"Data loaded!\")\n",
    "print(\"Reducing corpus...\")\n",
    "characters_to_replace = [ '\\n', '\\r', '\\t', '$']\n",
    "for character in characters_to_replace:\n",
    "    text = text.replace(character, \"\")\n",
    "\n",
    "text = text.replace(\"\\\"\", \" \")\n",
    "text = text.replace(\"  \", \" \")\n",
    "text = text.lower()\n",
    "\n",
    "corpus = sorted(list(set(text)))\n",
    "corpus_size = len(corpus)\n",
    "print(\"Reduced corpus:\")\n",
    "print(corpus)\n",
    "print(\"Data sample:\")\n",
    "print(text[500:1000])\n",
    "\n",
    "#limit num of samples to 500000, more will cause memory issues\n",
    "window_size = 50\n",
    "#num_of_samples = len(text)-(window_size+1)\n",
    "num_of_samples = 500000\n",
    "\n",
    "X = np.zeros((num_of_samples, window_size, corpus_size))\n",
    "y = np.zeros((num_of_samples, corpus_size))\n",
    "\n",
    "print(\"Getting samples...\")\n",
    "for i in range(num_of_samples):\n",
    "    window = get_window(text, i, window_size)\n",
    "    window_X, window_y = from_window_to_one_hot(window, corpus)\n",
    "    X[i] = window_X\n",
    "    y[i] = window_y\n",
    "\n",
    "print(\"Compiling model...\")\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=200, input_shape=(window_size, corpus_size)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=corpus_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "optimizer = keras.optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "print(\"Training model (may take a while)...\")\n",
    "number_of_epochs = 30\n",
    "for i in range(number_of_epochs):\n",
    "    model.fit(X, y, batch_size=500, epochs=1)\n",
    "    print(\"After\", i, \"epochs, model generated:\")\n",
    "    print(generate_sample(model))\n",
    "\n",
    "#Remember to update me before training!\n",
    "model.save('shakespeare4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d and the state of heaven, and then the state of the fields of the state. the sun in the field of the field. what say you to the protector of the see. the lord of were the commonwealth of the commons to the part of the seas of france, and then the state of the fields of the state of heaven, and then the state of the fields of the state. the sun in the field of the field. what say you to the protector of the see. the lord of were the commonwealth of the commons to the part of the seas of france, '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample(model, 500, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI_year_3)",
   "language": "python",
   "name": "labs_y3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
